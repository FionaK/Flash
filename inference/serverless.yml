service: flash-inference

provider:
  name: aws
  runtime: python3.8
  stage: dev
  region: us-east-1
  timeout: 30
  environment:
    S3_BUCKET: loovus
  iamRoleStatements:
    - Effect: 'Allow'
      Action:
        - s3:getObject
      Resource: arn:aws:s3:::loovus/*

custom:
  pythonRequirements:
    dockerizePip: true
    zip: true
    slim: true
    strip: false
    noDeploy:
      - docutils
      - jmespath
      - pip
      - python-dateutil
      - setuptools
      - six
      - tensorboard
    useStaticCache: true
    useDownloadCache: true
    cacheLocation: './cache'

package:
  individually: true
  exclude:
    - package.json
    - package-lock.json
    - node_modules/**
    - cache/**
    - test/**
    - .vscode/**
    - __pycache__/**
    - .pytest_cache/**

functions:
  check:
    handler: handler.check
    module: check
    memorySize: 3008 # MB
    timeout: 30 # seconds
    events:
      - http:
          path: check
          method: post
          cors: true
  inference:
    handler: handler.inference
    module: infer
    memorySize: 3008 # MB
    timeout: 30 # seconds
    events:
      - http:
          path: inference
          method: post
          cors: true

plugins:
  - serverless-python-requirements
